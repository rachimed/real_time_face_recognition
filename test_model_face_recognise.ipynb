{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Utilisateur\\Desktop\\ProjetIA\\Real_time_face_recognition\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test du model de prediction de personne:\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import  img_to_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Utilisateur\\Desktop\\ProjetIA\\Real_time_face_recognition\\.venv\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Utilisateur\\Desktop\\ProjetIA\\Real_time_face_recognition\\.venv\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chemin vers le modèle sauvegardé et le dossier de validation\n",
    "#model_path = './face_dataset/face_recognise_plus.h5'   # model\n",
    "model_path = './models/face_recognise_plus.h5'\n",
    "#model_path = '../models/face_recognition2.h5'\n",
    "model = load_model(model_path)\n",
    "labels= ['Rachida', 'Khalil', 'Vincent', 'Athman','Nicolas', 'Houssine', 'Yassine', 'Amina', 'Sofiane', 'Thibaut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path1 = '../face_dataset/dataset/User.1/1.4.jpg' #Rachida\n",
    "file_path2 = '../face_dataset/dataset/User.3/3.10.jpg' #Athman\n",
    "file_path3 = '../face_dataset/dataset/User.2/2.5.jpg' #Vincent\n",
    "file_path4 = '../face_dataset/dataset/User.5/6.5.jpg' #Houssine\n",
    "file_path5 = '../face_dataset/dataset/User.7/9.9.jpg' #Amina\n",
    "file_path6 = '../face_dataset/dataset/User.8/19.jpg' #Sofiane\n",
    "file_path7 = '../face_dataset/dataset/User.9/10.jpg' #Thibaut\n",
    "#file_path8 = '../face_dataset/dataset/User.10/25.jpg' #Khalil\n",
    "\n",
    "file_path11 = '../face_dataset/dataset/0_018_fcafe1a8.jpg' #Anjolina Joli (couleur)-inconnue\n",
    "file_path12 = '../face_dataset/dataset/0_43.jpg' #Inconnu (couleur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taille des images attendue par le modèle\n",
    "image_size = (250,250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(file_path, target_size=image_size):\n",
    "    # Charger l'image avec PIL\n",
    "    img = Image.open(file_path).convert('RGB')\n",
    "    img = img.resize(target_size)\n",
    "    img_array = np.array(img)\n",
    "    # Ajouter une dimension de batch\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_processed =  preprocess_input(img_array)\n",
    "\n",
    "    return img_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image1 = load_and_preprocess_image(file_path1)\n",
    "prediction1 = model.predict(image1)\n",
    "\n",
    "image2 = load_and_preprocess_image(file_path2)\n",
    "prediction2 = model.predict(image2)\n",
    "\n",
    "image3 = load_and_preprocess_image(file_path3)\n",
    "prediction3 = model.predict(image3)\n",
    "\n",
    "image4 = load_and_preprocess_image(file_path4)\n",
    "prediction4 = model.predict(image4)\n",
    "\n",
    "image5 = load_and_preprocess_image(file_path5)\n",
    "prediction5 = model.predict(image5)\n",
    "\n",
    "image6 = load_and_preprocess_image(file_path6)\n",
    "prediction6 = model.predict(image6)\n",
    "\n",
    "image7 = load_and_preprocess_image(file_path7)\n",
    "prediction7 = model.predict(image7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personne non reconnue\n"
     ]
    }
   ],
   "source": [
    "if np.max(prediction1) <0.5 : print('personne non reconnue')\n",
    "else: print( labels[np.argmax(prediction1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personne non reconnue\n"
     ]
    }
   ],
   "source": [
    "if np.max(prediction2) <0.5 : print('personne non reconnue')\n",
    "else: print( labels[np.argmax(prediction2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personne non reconnue\n"
     ]
    }
   ],
   "source": [
    "if np.max(prediction3) <0.5 : print('personne non reconnue')\n",
    "else: print( labels[np.argmax(prediction3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 142ms/step\n"
     ]
    }
   ],
   "source": [
    "file_pathAH = '../face_dataset/dataset/User.5/7.9.jpg'\n",
    "\n",
    "imageAH = load_and_preprocess_image(file_pathAH)\n",
    "predictionAH = model.predict(imageAH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Houssine\n"
     ]
    }
   ],
   "source": [
    "if np.max(prediction4) <0.6 : print('personne non reconnue')\n",
    "else: print( labels[np.argmax(prediction4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amina\n"
     ]
    }
   ],
   "source": [
    "if np.max(prediction5) <0.6 : print('personne non reconnue')\n",
    "else: print( labels[np.argmax(prediction5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personne non reconnue\n"
     ]
    }
   ],
   "source": [
    "if np.max(prediction6) <0.6 : print('personne non reconnue')\n",
    "else: print( labels[np.argmax(prediction6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personne non reconnue\n"
     ]
    }
   ],
   "source": [
    "if np.max(prediction7) <0.6 : print('personne non reconnue')\n",
    "else: print( labels[np.argmax(prediction7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Houssine\n"
     ]
    }
   ],
   "source": [
    "if np.max(predictionAH) <0.6 : print('personne non reconnue')\n",
    "else: print( labels[np.argmax(predictionAH)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction qui detect le visage et renvoie cette zone en mode gris\n",
    "def detect(gray): \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        return roi_gray  # Return face region \n",
    "    return None  # Return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# # Loading the cascades\n",
    "face_cascade = cv2.CascadeClassifier('../Haarcascades/haarcascade_frontalface_default.xml')\n",
    "#eye_cascade = cv2.CascadeClassifier('../Haarcascades/haarcascade_eye.xml')\n",
    "file_pathAH_camera= '../face_dataset/dataset/User.5/7.26.jpg'\n",
    "file_pathSof_camera= '../face_dataset/dataset/IMG_20231124_184547.jpg'\n",
    "file_pathTib_camera = '../face_dataset/dataset/IMG_20231125_122835.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img2 = cv2.imread(file_pathTib_camera)\n",
    "img1 = cv2.imread(file_pathSof_camera)\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "# Detect face\n",
    "      \n",
    "face_roi1= detect(gray1)\n",
    "face_roi2= detect(gray2)\n",
    "#dest_file_path = os.path.join(src_dir, file) \n",
    "img_path_SF= '../face_dataset/dataset/imgSF1.jpg'\n",
    "img_path_Tib= '../face_dataset/dataset/imgTib2.jpg'\n",
    "cv2.imwrite(img_path_SF, face_roi1)\n",
    "cv2.imwrite(img_path_Tib, face_roi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 212ms/step\n",
      "Sofiane\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "image1 = load_and_preprocess_image(img_path_SF)\n",
    "image2 = load_and_preprocess_image(img_path_Tib)\n",
    "# list_img = [face_roi1, face_roi2]\n",
    "# for face_roi in list_img\n",
    "  #if face_roi is not None:\n",
    "\n",
    "\n",
    "predictionSF= model.predict(image1)\n",
    "if np.max(predictionSF) <0.6 : print('personne non reconnue')\n",
    "else: print( labels[np.argmax(predictionSF)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 196ms/step\n",
      "Thibaut\n"
     ]
    }
   ],
   "source": [
    "predictionTib= model.predict(image2)\n",
    "if np.max(predictionTib) <0.6 : print('personne non reconnue')\n",
    "else: print( labels[np.argmax(predictionTib)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presonnes inconnues (externes du dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path13 = '../face_dataset/dataset/0_Image_23.jpg'\n",
    "file_path14 = '../face_dataset/dataset/0_027_7c6c360c.jpg'\n",
    "file_path15 = '../face_dataset/dataset/0_Image_18.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path16 = '../face_dataset/dataset/0_041_bcfa1766.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img13 = cv2.imread(file_path13)\n",
    "img14 = cv2.imread(file_path14)\n",
    "gray13 = cv2.cvtColor(img13, cv2.COLOR_BGR2GRAY)\n",
    "gray14 = cv2.cvtColor(img14, cv2.COLOR_BGR2GRAY)\n",
    "# Detect face\n",
    "if img14 is None:\n",
    "    print(\"Erreur lors du chargement de l'image 14\")     \n",
    "face_roi13= detect(gray13)\n",
    "face_roi14= detect(gray14)\n",
    "\n",
    "#dest_file_path = os.path.join(src_dir, file) \n",
    "img_path_13= '../face_dataset/dataset/temp/img13.jpg'\n",
    "img_path_14= '../face_dataset/dataset/temp/img14.jpg'\n",
    "cv2.imwrite(img_path_13, face_roi13)\n",
    "cv2.imwrite(img_path_14, face_roi14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face ROI returned by the detect function\n"
     ]
    }
   ],
   "source": [
    "img16 = cv2.imread(file_path16)\n",
    "gray16 = cv2.cvtColor(img16, cv2.COLOR_BGR2GRAY)\n",
    "if img16 is None:\n",
    "    print(\"Erreur lors du chargement de l'image 16\")  \n",
    "face_roi16= detect(gray16)\n",
    "\n",
    "if face_roi16 is not None:\n",
    "    img_path_16 = '../face_dataset/dataset/temp/img16.jpg'\n",
    "    cv2.imwrite(img_path_16, face_roi16)\n",
    "else:\n",
    "    print(\"No face ROI returned by the detect function\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:787: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Utilisateur\\Desktop\\ProjetIA\\Real_time_face_recognition\\models\\test_model_face_recognise-checkpoint.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Utilisateur/Desktop/ProjetIA/Real_time_face_recognition/models/test_model_face_recognise-checkpoint.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m img_path_16\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../face_dataset/dataset/temp/img16.jpg\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Utilisateur/Desktop/ProjetIA/Real_time_face_recognition/models/test_model_face_recognise-checkpoint.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m cv2\u001b[39m.\u001b[39mimwrite(img_path_15, face_roi15)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Utilisateur/Desktop/ProjetIA/Real_time_face_recognition/models/test_model_face_recognise-checkpoint.ipynb#X33sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m cv2\u001b[39m.\u001b[39;49mimwrite(img_path_16, face_roi16)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:787: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'\n"
     ]
    }
   ],
   "source": [
    "img15 = cv2.imread(file_path15)\n",
    "\n",
    "gray15 = cv2.cvtColor(img15, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect face\n",
    "   \n",
    "face_roi15= detect(gray15)\n",
    "\n",
    "\n",
    "#dest_file_path = os.path.join(src_dir, file) \n",
    "img_path_15= '../face_dataset/dataset/temp/img15.jpg'\n",
    "\n",
    "cv2.imwrite(img_path_15, face_roi15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_and_preprocess_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Utilisateur\\Desktop\\ProjetIA\\Real_time_face_recognition\\face_dataset\\test_model_face_recognise.ipynb Cell 29\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Utilisateur/Desktop/ProjetIA/Real_time_face_recognition/face_dataset/test_model_face_recognise.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m image14 \u001b[39m=\u001b[39m load_and_preprocess_image(img_path_14)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Utilisateur/Desktop/ProjetIA/Real_time_face_recognition/face_dataset/test_model_face_recognise.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m prediction14 \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(image14)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Utilisateur/Desktop/ProjetIA/Real_time_face_recognition/face_dataset/test_model_face_recognise.ipynb#X40sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mmax(prediction14) \u001b[39m<\u001b[39m\u001b[39m0.7\u001b[39m : \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mpersonne non reconnue\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_and_preprocess_image' is not defined"
     ]
    }
   ],
   "source": [
    "image14 = load_and_preprocess_image(img_path_14)\n",
    "prediction14 = model.predict(image14)\n",
    "if np.max(prediction14) <0.7 : print('personne non reconnue')\n",
    "else: print( labels[np.argmax(prediction14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 166ms/step\n",
      "personne non reconnue\n"
     ]
    }
   ],
   "source": [
    "img_path_11 = '../face_dataset/dataset/temp/AnjJoli.jpg' \n",
    "file_path12 = '../face_dataset/dataset/0_43.jpg' #Inconnu (couleur)\n",
    "image11 = load_and_preprocess_image(img_path_11)\n",
    "prediction11 = model.predict(image11)\n",
    "if np.max(prediction11) <0.7 : print('personne non reconnue')\n",
    "else: print( labels[np.argmax(prediction11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_path15' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Utilisateur\\Desktop\\ProjetIA\\Real_time_face_recognition\\face_dataset\\test_model_face_recognise.ipynb Cell 31\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Utilisateur/Desktop/ProjetIA/Real_time_face_recognition/face_dataset/test_model_face_recognise.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m image15 \u001b[39m=\u001b[39m load_and_preprocess_image(file_path15)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Utilisateur/Desktop/ProjetIA/Real_time_face_recognition/face_dataset/test_model_face_recognise.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m prediction15\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(image15)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Utilisateur/Desktop/ProjetIA/Real_time_face_recognition/face_dataset/test_model_face_recognise.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(prediction15)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'file_path15' is not defined"
     ]
    }
   ],
   "source": [
    "image15 = load_and_preprocess_image(file_path15)\n",
    "prediction15= model.predict(image15)\n",
    "print(prediction15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thibaut\n"
     ]
    }
   ],
   "source": [
    "if np.max(prediction15) <0.8 : print('personne non reconnue')\n",
    "else: print( labels[np.argmax(prediction15)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
